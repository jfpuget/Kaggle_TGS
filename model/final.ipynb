{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was written in a hurry and shoudl be cleaned. It is only shared because some of the competitors asked for it.  It hsould be refactored if anyone intend to reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label, binary_erosion, binary_dilation, disk\n",
    "from skimage.morphology import square, watershed, closing, binary_closing\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "from skimage.filters.rank import gradient\n",
    "from skimage.filters import sobel, scharr, prewitt, roberts\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.segmentation import random_walker\n",
    "from skimage.util import pad\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "#import cv2\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Add, Multiply, ZeroPadding2D\n",
    "from keras.layers.core import Dropout, Lambda, Dense\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers.merge import concatenate, Concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.engine import get_source_inputs\n",
    "from keras.utils import get_file, Sequence\n",
    "\n",
    "import keras\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
    "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "else:\n",
    "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "#from keras_util import ExponentialMovingAverage\n",
    "from segmentation_models import Unet\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle as pkl\n",
    "import gc\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '../input/train/'\n",
    "TEST_PATH = '../input/test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended way to remove noin determinism.  In addiiton, PYTHON_HASH_SEED was set to 0 before running notebooks.  Yet, repeated runs produce different outputs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "def init_seeds(seed):\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(seed)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    return sess\n",
    "\n",
    "sess = init_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "\n",
    "\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "\n",
    "\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_ids = train_df.index\n",
    "test_ids = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_mask = []\n",
    "\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    file = \"../input/train/images/{}.png\".format(id_)\n",
    "    mfile = \"../input/train/masks/{}.png\".format(id_)\n",
    "    image = (imread(file) / 255).astype('float32')\n",
    "    #image = rescale_intensity(image, out_range=np.uint8).astype('float32') / 255\n",
    "    mask = imread(mfile, as_gray=True) / 65535\n",
    "    train.append(image)\n",
    "    train_mask.append(mask)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "img_size = 101\n",
    "new_img_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.array(train_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for training time augmentation, and image resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_to_class(img):\n",
    "    val = np.sum(img) / (img.shape[0] * img.shape[1])\n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "coverage = [cov_to_class(img) for img in train_mask]\n",
    "coverage[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_mask(mask):\n",
    "    res = np.sum(mask, axis=0)\n",
    "    res = np.unique(res)\n",
    "    return len(res) == 2 and res[0] == 0 and res[1] == mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta(x, y, incr_sz=30, img_size=img_size):\n",
    "    if np.random.random()  < 0.33:\n",
    "        return x, y\n",
    "    incr = np.random.randint(incr_sz)\n",
    "    new_sz = incr_sz + img_size\n",
    "    x = resize(x, (new_sz, img_size), preserve_range=True, order=3)\n",
    "    y = resize(y, (new_sz, img_size), preserve_range=True, order=3)\n",
    "    y = 1 * (y > 0.5)\n",
    "    offset = np.random.randint(incr+1)\n",
    "    x = x[offset:offset+img_size]\n",
    "    y = y[offset:offset+img_size]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_resize(img, is_mask, new_img_size=new_img_size):\n",
    "    if is_mask:\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "    if new_img_size == 128:\n",
    "        img = pad(img, ((13, 14), (13, 14), (0, 0)), mode='reflect')\n",
    "    if new_img_size == 224:\n",
    "        img = resize(img, (202, 202), preserve_range=True, order=3)\n",
    "        img = pad(img, ((11, 11), (11, 11), (0, 0)), mode='reflect')\n",
    "    if new_img_size == 256:\n",
    "        img = resize(img, (202, 202), preserve_range=True, order=3)\n",
    "        img = pad(img, ((27, 27), (27, 27), (0, 0)), mode='reflect')\n",
    "    if is_mask:\n",
    "        img = (img > 0.5).astype('float32')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crop(img, new_img_size=new_img_size):\n",
    "    num_channel = 0 if len(img.shape) == 2 else img.shape[2]\n",
    "    if new_img_size == 128:\n",
    "        img = img[13:13+101, 13:13+101]\n",
    "    if new_img_size == 224:\n",
    "        img = img[11:11+202, 11:11+202]\n",
    "        if num_channel:\n",
    "            img = resize(img, (101, 101, num_channel), preserve_range=True, order=3)\n",
    "        else:\n",
    "            img = resize(img, (101, 101), preserve_range=True, order=3)\n",
    "    if new_img_size == 256:\n",
    "        img = img[27:27+202, 27:27+202]\n",
    "        if num_channel:\n",
    "            img = resize(img, (101, 101, num_channel), preserve_range=True, order=3)\n",
    "        else:\n",
    "            img = resize(img, (101, 101), preserve_range=True, order=3)\n",
    "    return img\n",
    "\n",
    "def my_crop_a(imgs, new_img_size=new_img_size):\n",
    "    imgs = [my_crop(img, new_img_size) for img in imgs]\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting images with very small or very large masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_mask(mask, thr=0.005):\n",
    "    res = np.mean(mask)\n",
    "    return (res < thr) and (res > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_mask(mask, thr=0.997):\n",
    "    res = np.mean(mask)\n",
    "    return (res > thr) and (res < 1-thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of down sample ground truth for deep supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_down_masks(y1):\n",
    "    y2 = [resize(m, (new_img_size//2, new_img_size//2), preserve_range=True, order=3) for m in (y1) ]\n",
    "    y3 = [resize(m, (new_img_size//4, new_img_size//4), preserve_range=True, order=3) for m in (y1) ]\n",
    "    y4 = [resize(m, (new_img_size//8, new_img_size//8), preserve_range=True, order=3) for m in (y1) ]\n",
    "    y5 = [resize(m, (8, 8), preserve_range=True, order=3) for m in (y1) ]\n",
    "    y2 = [(m > 0.5).astype('float32') for m in y2]\n",
    "    y3 = [(m > 0.5).astype('float32') for m in y3]\n",
    "    y4 = [(m > 0.5).astype('float32') for m in y4]\n",
    "    y5 = [(m > 0.5).astype('float32') for m in y5]\n",
    "    y2 = np.array(y2).reshape(-1, new_img_size//2, new_img_size//2, 1).astype('float32')\n",
    "    y3 = np.array(y3).reshape(-1, new_img_size//4, new_img_size//4, 1).astype('float32')\n",
    "    y4 = np.array(y4).reshape(-1, new_img_size//8, new_img_size//8, 1).astype('float32')\n",
    "    y5 = np.array(y5).reshape(-1, 8, 8, 1).astype('float32')\n",
    "    \n",
    "    y6 = np.amax(y1, axis=(1,2), keepdims=True)\n",
    "    \n",
    "    return [y1, y2, y3, y4, y5, y6, y1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for tta continued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(x_train, y_train):\n",
    "    x_train = [x for x,m in zip(x_train, y_train) if not vertical_mask(m)]\n",
    "    y_train = [m for m in y_train if not vertical_mask(m)]\n",
    "    \n",
    "    x_train = [x for x,m in zip(x_train, y_train) if not small_mask(m)]\n",
    "    y_train = [m for m in y_train if not small_mask(m)]\n",
    "\n",
    "    x_train = [x for x,m in zip(x_train, y_train) if not large_mask(m)]\n",
    "    y_train = [m for m in y_train if not large_mask(m)]\n",
    "\n",
    "    x_train = np.append(x_train, [np.fliplr(x) for x in (x_train)], axis=0)\n",
    "    y_train = np.append(y_train, [np.fliplr(x) for x in (y_train)], axis=0)\n",
    "\n",
    "    x_train = np.array(x_train).reshape(-1, img_size, img_size, num_channels).astype('float32')\n",
    "    y_train = np.array(y_train).reshape(-1, img_size, img_size, 1).astype('float32')\n",
    "        \n",
    "    return x_train, y_train\n",
    "\n",
    "def get_valid_data(x_valid, y_valid):\n",
    "    x_valid = np.append(x_valid, [np.fliplr(x) for x in (x_valid)], axis=0)\n",
    "    y_valid = np.append(y_valid, [np.fliplr(x) for x in (y_valid)], axis=0)\n",
    "\n",
    "    x_valid = [my_resize(x, is_mask=False) for x in (x_valid)]\n",
    "    y_valid = [my_resize(y, is_mask=True) for y in (y_valid)]\n",
    " \n",
    "    x_valid = np.array(x_valid).reshape(-1, new_img_size, new_img_size, num_channels).astype('float32')\n",
    "    y_valid = np.array(y_valid).reshape(-1, new_img_size, new_img_size, 1).astype('float32')\n",
    "    \n",
    "    y_valid = get_down_masks(y_valid)\n",
    "\n",
    "    return x_valid, y_valid\n",
    "\n",
    "def get_valid_data_noflip(x_valid, y_valid):\n",
    "    x_valid = [my_resize(x, is_mask=False) for x in (x_valid)]\n",
    "    y_valid = [my_resize(y, is_mask=True) for y in (y_valid)]\n",
    " \n",
    "    x_valid = np.array(x_valid).reshape(-1, new_img_size, new_img_size, num_channels).astype('float32')\n",
    "    y_valid = np.array(y_valid).reshape(-1, new_img_size, new_img_size, 1).astype('float32')\n",
    "    \n",
    "    y_valid = get_down_masks(y_valid)\n",
    "\n",
    "    return x_valid, y_valid\n",
    "\n",
    "def get_test_data(test):\n",
    "    x_test = [my_resize(x, is_mask=False) for x in (test)]\n",
    "    x_test = np.array(x_test).reshape(-1, new_img_size, new_img_size, num_channels).astype('float32')\n",
    "    return x_test\n",
    "\n",
    "\n",
    "def tta_train_data(x_train, y_train):\n",
    "    #Data augmentation\n",
    "\n",
    "    v_aug1 = [tta(x, y) for x,y in zip((x_train), y_train)]\n",
    "    x_train = [x for x,y in v_aug1]\n",
    "    y_train = [y for x,y in v_aug1]\n",
    "\n",
    "    x_train = [my_resize(x, is_mask=False) for x in (x_train)]\n",
    "    y_train = [my_resize(x, is_mask=True) for x in (y_train)]\n",
    "\n",
    "    x_train = np.array(x_train).reshape(-1, new_img_size, new_img_size, num_channels).astype('float32')\n",
    "    y_train = np.array(y_train).reshape(-1, new_img_size, new_img_size, 1).astype('float32')\n",
    "\n",
    "    y_train = get_down_masks(y_train)\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence for streaming upsampled data and for triauning time augmentation.  I should have created one for validation and for test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGS_train_seq(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        p = np.random.permutation(x_set.shape[0])\n",
    "        self.x, self.y = x_set[p], y_set[p]\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return tta_train_data(batch_x, batch_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast metric computation.  Way faster than the one used by organizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B, new_img_size=new_img_size):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    if new_img_size == 128 and A.shape[1] == new_img_size:\n",
    "        A = A[:, 13:13+101, 13:13+101]\n",
    "        B = B[:, 13:13+101, 13:13+101]\n",
    "    if new_img_size == 224 and A.shape[1] == new_img_size:\n",
    "        A = A[:, 11:11+202, 11:11+202]\n",
    "        B = B[:, 11:11+202, 11:11+202]\n",
    "    if new_img_size == 256 and A.shape[1] == new_img_size:\n",
    "        A = A[:, 27:27+202, 27:27+202]\n",
    "        B = B[:, 27:27+202, 27:27+202]\n",
    "        \n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        iou = min(1, np.floor(max(0, (iou - 0.45)*20)) / 10)\n",
    "        \n",
    "        metric += iou\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def iou_m(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Focal loss.  Gamma = 1, and alpha computed per image.\n",
    "\n",
    "https://arxiv.org/abs/1708.02002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "def pixelwise_crossentropy(target, output):\n",
    "    _epsilon = 10e-8\n",
    "    output = K.sigmoid(output)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n",
    "    cov =  tf.reduce_sum(target, [1, 2], keepdims=True) / tf.cast((tf.shape(target)[1]**2), 'float32')\n",
    "    pos_weight = 0.5 / (cov + epsilon)\n",
    "    neg_weight = 0.5 / (1 - cov + epsilon)\n",
    "    \n",
    "    return - tf.reduce_sum(target * pos_weight *  (1. - output) * tf.log(output) +\n",
    "                           (1 - target)  *  neg_weight * output * tf.log(1 - output),\n",
    "                           len(output.get_shape()) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovasz loss.\n",
    "\n",
    "Simplified the code downloaded from: https://github.com/bermanmaxim/LovaszSoftmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet using pretrained resnet34 encoder from https://github.com/qubvel/segmentation_models\n",
    "\n",
    "Modified for deep supervision and for empty mask classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DEEP_CONNECTIONS = {\n",
    "    'resnet34':  ['decoder_stage%d_relu2' % i for i in range(3, 0, -1)] + ['relu1'],\n",
    "    'resnext50': ['decoder_stage%d_relu2' % i for i in range(3, 0, -1)] + ['stage4_unit3_relu'],\n",
    "}\n",
    "\n",
    "def get_deep_connection(backbone):\n",
    "    return DEFAULT_DEEP_CONNECTIONS[backbone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_number(model, layer_name):\n",
    "    \"\"\"\n",
    "    Help find layer in Keras model by name\n",
    "    Args:\n",
    "        model: Keras `Model`\n",
    "        layer_name: str, name of layer\n",
    "    Returns:\n",
    "        index of layer\n",
    "    Raises:\n",
    "        ValueError: if model does not contains layer with such name\n",
    "    \"\"\"\n",
    "    #print(layer_name)\n",
    "    for i, l in enumerate(model.layers):\n",
    "        if l.name == layer_name:\n",
    "            return i\n",
    "    raise ValueError('No layer with name {} in  model {}.'.format(layer_name, model.name))\n",
    "\n",
    "def extract_outputs(model, layers, include_top=False):\n",
    "    \"\"\"\n",
    "    Help extract intermediate layer outputs from model\n",
    "    Args:\n",
    "        model: Keras `Model`\n",
    "        layer: list of integers/str, list of layers indexes or names to extract output\n",
    "        include_top: bool, include final model layer output\n",
    "    Returns:\n",
    "        list of tensors (outputs)\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(layers)\n",
    "    layers_indexes = ([get_layer_number(model, l) if isinstance(l, str) else l\n",
    "                      for l in layers])\n",
    "    outputs = [model.layers[i].output for i in layers_indexes]\n",
    "\n",
    "    if include_top:\n",
    "        outputs.insert(0, model.output)\n",
    "    #print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone_name, input_shape):\n",
    "    model = Unet(backbone_name=backbone_name, encoder_weights='imagenet',\n",
    "                  decoder_block_type='transpose', activation=None, input_shape=input_shape,\n",
    "                 )\n",
    "    deep_connections = get_deep_connection(backbone_name)\n",
    "    \n",
    "    #print(deep_connections)\n",
    "\n",
    "    deep_connection_outputs = extract_outputs(model, deep_connections) \n",
    "\n",
    "    output_layers_no_acti = [ Conv2D(1, (1,1), \n",
    "                                    padding=\"same\", activation=None, \n",
    "                                    name='o_%i' % i)(output) for i,output in enumerate(deep_connection_outputs)]    \n",
    "    output_layers_no_acti = [model.output] + output_layers_no_acti\n",
    "    non_empty = AveragePooling2D((8, 8))(deep_connection_outputs[-1])\n",
    "   \n",
    "    output_non_empty_noActi = Dense(1, activation='linear', name='non_empty')(non_empty)\n",
    "    \n",
    "    full_output_noActi = Add(name='full')([model.output, output_non_empty_noActi])\n",
    "    \n",
    "    outputs_noActi = output_layers_no_acti + [output_non_empty_noActi, full_output_noActi]\n",
    "    model_1 = Model(model.input, outputs_noActi)\n",
    "    return model_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 fold training.  50 epochs with pixeclwise cross entropy, then 6 with Lovasz Loss for the final segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(7, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train, coverage)):\n",
    "    print('***************************************************')\n",
    "    print('*******************   fold  %d   *******************' % fold)\n",
    "    print('***************************************************')\n",
    "\n",
    "    basic_name = 'Unet_'+fname+'_fold_%d'%fold\n",
    "    save_model_name = basic_name + '.model'\n",
    "    print(save_model_name)\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    sess = init_seeds(0)\n",
    "    \n",
    "    x_train = train[train_idx]\n",
    "    y_train = train_mask[train_idx]\n",
    "    x_valid = train[val_idx]\n",
    "    y_valid = train_mask[val_idx]\n",
    "    x_train, y_train = get_train_data(x_train, y_train)\n",
    "    x_valid, y_valid = get_valid_data(x_valid, y_valid)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_seq = TGS_train_seq(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "    model1 = build_model(backbone_name='resnet34', input_shape=(new_img_size, new_img_size, num_channels)\n",
    "                 )\n",
    "    if fold == 0:\n",
    "        model1.summary()\n",
    "\n",
    "    c = Adam(lr=0.001)\n",
    "    weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0]\n",
    "    sum_weights = np.sum(weights)\n",
    "    loss_weights = [w/sum_weights for w in weights]\n",
    "    #loss_weights = [1.]\n",
    "    model1.compile(loss=pixelwise_crossentropy, optimizer=c, metrics=[iou_m],\n",
    "                   loss_weights=loss_weights)\n",
    "\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name, monitor='val_full_iou_m', save_weights_only=True,\n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_full_iou_m', mode = 'max',factor=0.5, \n",
    "                                  patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "    epochs = 50\n",
    "    history = model1.fit_generator(train_seq,\n",
    "                                    validation_data=[x_valid, y_valid], \n",
    "                                    epochs=epochs,\n",
    "                                    callbacks=[ model_checkpoint, reduce_lr], \n",
    "                                    verbose=1,\n",
    "                                  shuffle=True)\n",
    "\n",
    "    fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax_loss.plot(history.epoch, history.history[\"full_loss\"], label=\"Train loss\")\n",
    "    ax_loss.plot(history.epoch, history.history[\"val_full_loss\"], label=\"Validation loss\")\n",
    "    ax_loss.legend()\n",
    "    ax_score.plot(history.epoch, history.history[\"full_iou_m\"], label=\"Train score\")\n",
    "    ax_score.plot(history.epoch, history.history[\"val_full_iou_m\"], label=\"Validation score\")\n",
    "    ax_score.legend()\n",
    "\n",
    "    save_model_name2 = basic_name + '_2.model'\n",
    "\n",
    "    print(save_model_name2)\n",
    "\n",
    "\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    sess = init_seeds(0)\n",
    "\n",
    "    model1 = build_model(backbone_name='resnet34', input_shape=(new_img_size, new_img_size, num_channels))\n",
    "    model1.load_weights(save_model_name)\n",
    " \n",
    "    c = Adam(lr = 0.0005, clipvalue=1)\n",
    "    loss = [pixelwise_crossentropy, pixelwise_crossentropy, pixelwise_crossentropy, \n",
    "           pixelwise_crossentropy, pixelwise_crossentropy, pixelwise_crossentropy,\n",
    "            lovasz_loss\n",
    "           ]\n",
    "    model1.compile(loss=loss, optimizer=c, metrics=[iou_m],\n",
    "                   loss_weights=loss_weights)\n",
    "    #model1.summary()\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name2, monitor='val_full_iou_m', save_weights_only=True, \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_full_iou_m', mode = 'max',factor=0.5, \n",
    "                                  patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "    epochs = 36\n",
    "    batch_size = 16\n",
    "    history = model1.fit_generator(train_seq,\n",
    "                                    validation_data=[x_valid, y_valid], \n",
    "                                    epochs=epochs,\n",
    "                                    callbacks=[ model_checkpoint, reduce_lr], \n",
    "                                    verbose=1,\n",
    "                                  shuffle=True)\n",
    "\n",
    "    fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax_loss.plot(history.epoch, history.history[\"full_loss\"], label=\"Train loss\")\n",
    "    ax_loss.plot(history.epoch, history.history[\"val_full_loss\"], label=\"Validation loss\")\n",
    "    ax_loss.legend()\n",
    "    ax_score.plot(history.epoch, history.history[\"full_iou_m\"], label=\"Train score\")\n",
    "    ax_score.plot(history.epoch, history.history[\"val_full_iou_m\"], label=\"Validation score\")\n",
    "    ax_score.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for best model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model, x_test, img_size): # predict both orginal and reflect x\n",
    "    x_test_reflect = [my_crop(x) for x in x_test]\n",
    "    x_test_reflect = [np.fliplr(x) for x in x_test_reflect]\n",
    "    x_test_reflect = [my_resize(x, is_mask=False) for x in x_test_reflect]\n",
    "    x_test_reflect = np.array(x_test_reflect)\n",
    "    preds_test = model.predict(x_test)[-1].reshape(-1, new_img_size, new_img_size)\n",
    "    preds_test2_refect = model.predict(x_test_reflect)[-1].reshape(-1, new_img_size, new_img_size)\n",
    "    preds_test = my_crop_a(preds_test)\n",
    "    preds_test2_refect = my_crop_a(preds_test2_refect)\n",
    "    preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test, preds_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred, threshold, verbose=False, ret_all=False):\n",
    "    y_true = y_true.flatten() \n",
    "    y_pred = 1 * (y_pred.flatten() > threshold)\n",
    "    inter = y_true * y_pred\n",
    "    union = y_true + y_pred - inter\n",
    "    true_size = np.sum(y_true)\n",
    "    pred_size = np.sum(y_pred)\n",
    "    inter_size = np.sum(inter)\n",
    "    union_size = np.sum(union)\n",
    "    iou = np.sum(inter) / np.sum(union)\n",
    "    if verbose:\n",
    "        print(true_size, pred_size, inter_size, union_size)\n",
    "    if true_size == 0:\n",
    "        if ret_all:\n",
    "            return 1 * (pred_size == 0), true_size, pred_size, inter_size, union_size\n",
    "        return 1 * (pred_size == 0)\n",
    "    iou = min(1, np.floor(max(0, (iou - 0.45)*20)) / 10)\n",
    "    if ret_all:\n",
    "        return iou, true_size, pred_size, inter_size, union_size\n",
    "    return  iou\n",
    "\n",
    "def iou_mean(thr, y_valid, pred_valid):\n",
    "    data=([iou_coef(y_valid[idx], pred_valid[idx], thr, verbose=False, ret_all=False) \\\n",
    "                        for idx in range(len(y_valid))])\n",
    "    return np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids)):\n",
    "    file = \"../input/test/images/{}.png\".format(id_)\n",
    "    image = (imread(file) / 255).astype('float32')\n",
    "    #image = rescale_intensity(image, out_range=np.uint8).astype('float32') / 255\n",
    "    test.append(image)\n",
    "    \n",
    "x_test = get_test_data(test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute score for each fold.  \n",
    "\n",
    "Combpute best threshold (not used for final submission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_valids = []\n",
    "valid_preds = []\n",
    "\n",
    "kf = StratifiedKFold(7, shuffle=True, random_state=0)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train, coverage)):\n",
    "        \n",
    "    print('*******************   fold  %d   *******************' % fold)\n",
    "\n",
    "    basic_name = 'Unet_'+fname+'_fold_%d'%fold\n",
    "    \n",
    "    save_model_name2 = basic_name + '_2.model'\n",
    "\n",
    "    print(save_model_name2)\n",
    "    \n",
    "    x_valid = train[val_idx]\n",
    "    y_valid = train_mask[val_idx]\n",
    "    x_valid, y_valid = get_valid_data_noflip(x_valid, y_valid)\n",
    "\n",
    "    y_valid = train_mask[val_idx]\n",
    "    \n",
    "\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    sess = init_seeds(0)\n",
    "\n",
    "    model1 = build_model(backbone_name='resnet34', input_shape=(new_img_size, new_img_size, num_channels))\n",
    "    model1.load_weights(save_model_name2)\n",
    "\n",
    "\n",
    "    pred_valid, pred_valid2 = predict_result(model1, x_valid, img_size)\n",
    "\n",
    "\n",
    "    pred1 = expit((pred_valid + pred_valid2) / 2)\n",
    "    \n",
    "    \n",
    "    ious = [iou_mean(thr, y_valid, pred1) for thr in np.linspace(0, 1, 101)]\n",
    "\n",
    "\n",
    "    threshold_best = np.argmax(ious)\n",
    "    \n",
    "    print(threshold_best/100, ious[threshold_best])\n",
    "    y_valids.append(y_valid)\n",
    "    valid_preds.append(pred1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute test prediction and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.zeros((18000, 101, 101))\n",
    "\n",
    "kf = StratifiedKFold(7, shuffle=True, random_state=0)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train, coverage)):\n",
    "        \n",
    "    print('*******************   fold  %d   *******************' % fold)\n",
    "\n",
    "    basic_name = 'Unet_'+fname+'_fold_%d'%fold\n",
    "    \n",
    "    save_model_name2 = basic_name + '_2.model'\n",
    "\n",
    "    print(save_model_name2)\n",
    "    \n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    sess = init_seeds(0)\n",
    "\n",
    "    model1 = build_model(backbone_name='resnet34', input_shape=(new_img_size, new_img_size, num_channels))\n",
    "    model1.load_weights(save_model_name2)\n",
    "\n",
    "    for i in tqdm_notebook(range(0, 18000, 1000)):\n",
    "        pred_test, pred_test1 = predict_result(model1, x_test[i:i+1000], img_size)\n",
    "\n",
    "        pred2 = (pred_test + pred_test1) / 2\n",
    "        test_preds[i:i+1000] += expit(pred2)\n",
    "test_preds /= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = '../submissions/'+fname+'_all_expit.csv'\n",
    "\n",
    "print(submission_file)\n",
    "\n",
    "pred_dict = {idx: rle_encode(test_preds[i] > 0.5) for i, idx in enumerate(tqdm_notebook(test_ids))}\n",
    "\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)\n",
    "\n",
    "\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fold and test raw prediciton for ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "with open('../data/%s_all_valid_preds_all.pkl' % fname, 'wb') as file:\n",
    "    pkl.dump(all_valid_preds, file)   \n",
    "\n",
    "with open('../data/%s_pred_test_all.pkl' % fname, 'wb') as file:\n",
    "    pkl.dump(test_preds, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf110]",
   "language": "python",
   "name": "conda-env-tf110-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
